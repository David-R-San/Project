{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNvruczGCtnr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.sql.functions import lit, col, when\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from google.colab import drive\n",
        "\n",
        "# üöÄ Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# üìÇ Caminho do arquivo no Google Drive\n",
        "input_file = \"/content/drive/My Drive/3WDataset/dados_limpos_todasClasses.parquet\"\n",
        "\n",
        "# Configurar a sess√£o do Spark\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .appName(\"PySparkRandomForestColab\")\n",
        "    .config(\"spark.executor.memory\", \"11g\")\n",
        "    .config(\"spark.driver.memory\", \"8g\")\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"12\")\n",
        "    .getOrCreate()\n",
        ")\n",
        "\n",
        "# üîπ Fun√ß√£o para carregar e pr√©-processar os dados\n",
        "def load_and_preprocess_data(file_path):\n",
        "    start_time = time.time()\n",
        "    print(\"Iniciando o carregamento e pr√©-processamento dos dados...\")\n",
        "\n",
        "    # Carregar os dados usando PySpark\n",
        "    data = spark.read.parquet(file_path)\n",
        "\n",
        "    # Filtrar classes relevantes (0 a 9)\n",
        "    data = data.filter(data[\"class\"].isin([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n",
        "\n",
        "    # Montar o vetor de features\n",
        "    feature_columns = [col for col in data.columns if col not in [\"class\", \"state\"]]\n",
        "    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "    data = assembler.transform(data)\n",
        "\n",
        "    # Normalizar as features\n",
        "    scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
        "    scaler_model = scaler.fit(data)\n",
        "    data = scaler_model.transform(data)\n",
        "\n",
        "    # Calcular pesos das classes\n",
        "    print(\"\\nCalculando os pesos das classes...\")\n",
        "    class_counts = data.groupBy(\"class\").count().toPandas()\n",
        "    total_count = class_counts[\"count\"].sum()\n",
        "    class_weights = {row[\"class\"]: total_count / row[\"count\"] for _, row in class_counts.iterrows()}\n",
        "    print(f\"Pesos das classes: {class_weights}\")\n",
        "\n",
        "    # Adicionar a coluna de pesos ao dataset\n",
        "    data = data.withColumn(\"classWeight\", lit(1))\n",
        "    for cls, weight in class_weights.items():\n",
        "        data = data.withColumn(\n",
        "            \"classWeight\",\n",
        "            when(col(\"class\") == cls, weight).otherwise(col(\"classWeight\"))\n",
        "        )\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"Carregamento e pr√©-processamento conclu√≠dos. Tempo: {elapsed_time:.2f} segundos\")\n",
        "    return data, elapsed_time\n",
        "\n",
        "# üîπ Fun√ß√£o para treinar o modelo Random Forest e calcular matriz de confus√£o\n",
        "def train_random_forest_and_confusion_matrix(data):\n",
        "    start_time = time.time()\n",
        "    print(\"Iniciando o treinamento do modelo Random Forest...\")\n",
        "\n",
        "    # Dividir os dados em treino e teste\n",
        "    train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "    # Criar e treinar o modelo com pesos das classes\n",
        "    rf = RandomForestClassifier(labelCol=\"class\", featuresCol=\"scaledFeatures\", weightCol=\"classWeight\", numTrees=100, maxDepth=10)\n",
        "    model = rf.fit(train_data)\n",
        "\n",
        "    # Fazer previs√µes\n",
        "    predictions = model.transform(test_data)\n",
        "\n",
        "    # Avaliar o modelo\n",
        "    evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"class\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "    evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"class\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "\n",
        "    balanced_accuracy = evaluator_acc.evaluate(predictions)\n",
        "    macro_f1_score = evaluator_f1.evaluate(predictions)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"Treinamento e avalia√ß√£o conclu√≠dos. Tempo: {elapsed_time:.2f} segundos\")\n",
        "    print(f\"Acur√°cia Balanceada: {balanced_accuracy:.4f}\")\n",
        "    print(f\"Macro F1-Score: {macro_f1_score:.4f}\")\n",
        "\n",
        "    # üìå Criar a matriz de confus√£o\n",
        "    print(\"Calculando a matriz de confus√£o...\")\n",
        "    confusion_df = (\n",
        "        predictions.groupBy(\"class\", \"prediction\")\n",
        "        .count()\n",
        "        .toPandas()\n",
        "        .pivot(index=\"class\", columns=\"prediction\", values=\"count\")\n",
        "        .fillna(0)\n",
        "    )\n",
        "\n",
        "    # Garantir que todas as classes est√£o na matriz de confus√£o\n",
        "    for cls in range(10):\n",
        "        if cls not in confusion_df.index:\n",
        "            confusion_df.loc[cls] = 0\n",
        "        if cls not in confusion_df.columns:\n",
        "            confusion_df[cls] = 0\n",
        "\n",
        "    confusion_df = confusion_df.sort_index(axis=0).sort_index(axis=1)\n",
        "\n",
        "    # Calcular a acur√°cia por classe\n",
        "    total_per_class = confusion_df.sum(axis=1)\n",
        "    correct_per_class = confusion_df.values.diagonal()\n",
        "    accuracy_per_class = correct_per_class / total_per_class\n",
        "\n",
        "    print(\"\\nAcur√°cia por classe:\")\n",
        "    for cls, acc in enumerate(accuracy_per_class):\n",
        "        print(f\"Classe {cls}: {acc:.4f}\")\n",
        "\n",
        "    return model, elapsed_time, balanced_accuracy, macro_f1_score, confusion_df, accuracy_per_class\n",
        "\n",
        "# üìå Executar pipeline completo\n",
        "overall_start_time = time.time()\n",
        "\n",
        "# üìÇ Etapa 1: Carregar e pr√©-processar os dados\n",
        "data, preprocessing_time = load_and_preprocess_data(input_file)\n",
        "\n",
        "# üî• Etapa 2: Treinar e avaliar o modelo\n",
        "model, training_time, balanced_accuracy, macro_f1_score, confusion_df, accuracy_per_class = train_random_forest_and_confusion_matrix(data)\n",
        "\n",
        "# üîπ Exibir tempo total de execu√ß√£o\n",
        "overall_elapsed_time = time.time() - overall_start_time\n",
        "print(\"\\nResumo de execu√ß√£o:\")\n",
        "print(f\"Tempo de carregamento e pr√©-processamento: {preprocessing_time:.2f} segundos\")\n",
        "print(f\"Tempo de treinamento e avalia√ß√£o: {training_time:.2f} segundos\")\n",
        "print(f\"Tempo total de execu√ß√£o: {overall_elapsed_time:.2f} segundos\")\n",
        "print(f\"Acur√°cia Balanceada: {balanced_accuracy:.4f}\")\n",
        "print(f\"Macro F1-Score: {macro_f1_score:.4f}\")\n",
        "\n",
        "# üìä Exibir matriz de confus√£o\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_df, annot=True, fmt=\".0f\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predito\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.title(\"Matriz de Confus√£o - Random Forest (Spark ML)\")\n",
        "plt.show()\n",
        "\n",
        "# Finalizar Spark\n",
        "spark.stop()\n",
        "print(\"Execu√ß√£o conclu√≠da.\")"
      ]
    }
  ]
}